<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pranita Sharma on Pranita Sharma</title>
    <link>https://pranita-s.github.io/</link>
    <description>Recent content in Pranita Sharma on Pranita Sharma</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Peculiar Case of Environments</title>
      <link>https://pranita-s.github.io/post/envs/</link>
      <pubDate>Sun, 08 Jul 2018 00:00:00 +0530</pubDate>
      
      <guid>https://pranita-s.github.io/post/envs/</guid>
      <description>

&lt;p&gt;After in depth analysis and various permutations of testing environments, we figured out that in the journey to code &lt;strong&gt;check_retriever()&lt;/strong&gt; function for &lt;strong&gt;rdataretriever&lt;/strong&gt; package, the most difficult hurdle to overcome is not different operating systems (Linux, Windows, MacOS). Its actually the existance of different virtual environments in the system.&lt;/p&gt;

&lt;p&gt;When there are more than one virtual environments in the system, a whole new spectrum of possibilities come into picture:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The user might have &lt;strong&gt;Retriever&lt;/strong&gt; installed in any one of the environments&lt;/li&gt;
&lt;li&gt;While executing &lt;strong&gt;R&lt;/strong&gt; code, it might be possible that the execution and existence of &lt;strong&gt;Retriever&lt;/strong&gt; package are in different environments.&lt;/li&gt;
&lt;li&gt;Or, both of them are in same environment.&lt;/li&gt;
&lt;li&gt;It might be also possible that the user is executing &lt;strong&gt;R&lt;/strong&gt; in a normal system environment and the package is present in a virtual environment.&lt;/li&gt;
&lt;li&gt;Over all these likelihoods, the user could be executing &lt;strong&gt;R&lt;/strong&gt; code through the &lt;strong&gt;R terminal&lt;/strong&gt; or &lt;strong&gt;RStudio&lt;/strong&gt;. This is one of the uncertainties that bug &lt;strong&gt;R&lt;/strong&gt; users the most. The reason being, the way &lt;strong&gt;R&lt;/strong&gt; finds and interprets paths in the systems, is completely different for terminal and IDE. Terminal uses system variables and &lt;strong&gt;RStudio&lt;/strong&gt; uses its own variables, which are entirely different.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;approaches-that-did-not-work&#34;&gt;Approaches that did not work&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The very first was using system terminal commands such as &lt;strong&gt;which&lt;/strong&gt; in Linux based OS and &lt;strong&gt;where&lt;/strong&gt; in Windows, but it appeared to be a inept way to solve the issue as it did not really work for Mac OS. Also, the terminal and IDE execution produced different outputs in terms of paths.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The next solution was leveraging the capabilities of the functions of &lt;strong&gt;Reticulate&lt;/strong&gt;. It has a amazing function &lt;strong&gt;py_config()&lt;/strong&gt; which tracks all the &lt;strong&gt;Python&lt;/strong&gt; version in the system and identifies their path. The approach was to use these paths, and append them to the &lt;strong&gt;Sys.getenv(&amp;lsquo;PATH&amp;rsquo;)&lt;/strong&gt; variable. After this &lt;strong&gt;R&lt;/strong&gt; can try to find &lt;strong&gt;Retriever&lt;/strong&gt; in these locations using &lt;strong&gt;Sys.which()&lt;/strong&gt;. Assuming that &lt;strong&gt;py_config()&lt;/strong&gt; is able to track down all the &lt;strong&gt;Python&lt;/strong&gt; versions, this approach seemed bullet-proof, because if &lt;strong&gt;Retriever&lt;/strong&gt; is not found in any of the paths appended, then it surely does not exist in the system.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The problem was the assumption that &lt;strong&gt;py_config()&lt;/strong&gt; is able to search all the &lt;strong&gt;Python&lt;/strong&gt; versions in the system. In reality, it did not. And the culprit is the existence of multiple virtual environments. The function cannot find &lt;strong&gt;Retriever&lt;/strong&gt; is present in any of the environments except the current.&lt;/p&gt;

&lt;h2 id=&#34;approach-implemented&#34;&gt;Approach Implemented&lt;/h2&gt;

&lt;p&gt;The bottom-line conclusion of all the failures encountered while trying to come out with an invincible function which can track &lt;strong&gt;Retriever&lt;/strong&gt; in the system no matter what is the permutation of OS, virtual environment, Python installation, IDE/Terminal etc., is giving the user the flexibility of feeding in the required path to the &lt;strong&gt;rdataretriever&lt;/strong&gt; package of &lt;strong&gt;R&lt;/strong&gt;. This is done by a new function &lt;strong&gt;use_RetrieverPath()&lt;/strong&gt; which takes in the path and appends it to the &lt;strong&gt;PATH&lt;/strong&gt; variable. This works with terminal/IDE and different operating systems. The important factor is, even if the the user is not present in the same environment as the &lt;strong&gt;Retriever&lt;/strong&gt;, it can still access it from a different environment if its path is already known.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pursuit of Python</title>
      <link>https://pranita-s.github.io/post/searchpython/</link>
      <pubDate>Mon, 11 Jun 2018 00:00:00 +0530</pubDate>
      
      <guid>https://pranita-s.github.io/post/searchpython/</guid>
      <description>

&lt;p&gt;Pursuit of Reticulate package in Windows is tricky than searching its installation in Ubuntu/Mac. Windows operating system has disintegrated structure for file storage. It also has different drives such as C,D etc. which can be the home for software installation. Over this layer of complicated file structure comes the different ways in which Python can be installed in the Windows OS. It can be a manual installation of &lt;strong&gt;python.exe&lt;/strong&gt; or through frameworks such as &lt;strong&gt;Miniconda&lt;/strong&gt;, &lt;strong&gt;Anaconda&lt;/strong&gt;. This overlaying complications make the location of Python and its containing packages very unpredictable. Also, the search should be successful if the code in executed from the terminal or within IDE such as RStudio. I tried my best to go through proper research before writing my code for this convoluted &lt;strong&gt;pursuit&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;literature-survey&#34;&gt;Literature Survey&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The current code for checking Reticulate installation in Windows adds all predicatable paths in which Python could have been installed taking into consideration manual as well as platform based installations. Then, these are added to the RStudio&amp;rsquo;s environment PATH so that RStudio can locate &lt;strong&gt;Reticulate&lt;/strong&gt;. The underlying disadvantage with this approach is the fact that, we cannot predict all the paths where Python could have been installed. During manual installation of Python, it could have been possible that the user gave its custom created directory as its location. This path, cannot be predicted for adding in the list of possible paths. Therefore, a more robust and flexibe approach is needed for this intricate pursuit.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;PythonInR&lt;/strong&gt; is a R package which allows the user to interact with Python from R environment. I studied its source code to understand how it is locating Python as its crucial step for the successfull package working. It has a function named &lt;strong&gt;autodetectPython.R&lt;/strong&gt; which accomplishes this task. It tries to locate Python using &lt;strong&gt;where&lt;/strong&gt; command in the terminal then filter the searches according to the &amp;ldquo;arch&amp;rdquo; of R version. Henceforth, it tries of locate dll file of Python for final connection&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;approach-implemented&#34;&gt;Approach Implemented&lt;/h2&gt;

&lt;p&gt;The proposal I wrote for solving this problem used a command called &lt;strong&gt;which&lt;/strong&gt; from the terminal. I tried to emulate the same process of &lt;strong&gt;which&lt;/strong&gt; command of R. With the Windows 8, the terminal command was working like the command of R. The search needs to be carried out from the home directory containing the software to be searched. For example, if Reticulate is present in D drive, searching need to be started from the top most directory of the drive to find it. If the search begins from any other drive, say C, the search will be unsuccessful.&lt;/p&gt;

&lt;p&gt;But the trouble occurred, when I realised that, &amp;ldquo;which&amp;rdquo; terminal command was not present in Windows 10 and Windows 7 by default. Hence, I am currently using &lt;strong&gt;where&lt;/strong&gt; command to carry out the search for Reticulate. I have checked that it is present in all the Windows. The best part of &lt;strong&gt;where&lt;/strong&gt; command is that it can search for any entity irrespective of its current location. For example, if the current location is in C drive, an entity present in D Drive can be retrived. Therefore, it will take care of the different ways of Python installation as well as the complicated file structure of Windows.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Power of Reticulate</title>
      <link>https://pranita-s.github.io/post/reticulate/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0530</pubDate>
      
      <guid>https://pranita-s.github.io/post/reticulate/</guid>
      <description>&lt;p&gt;It is been two weeks, since my last post about my GSoC selection. The first task assigned to me was writing a versatile install function for R API which will be at par in terms of functionalities of Python API. Earlier during my proposal preparation, I focussed on the need of configuration details required by databases such as &lt;strong&gt;PostgreSQL&lt;/strong&gt;,&lt;strong&gt;MySQL&lt;/strong&gt;,&lt;strong&gt;SQLite&lt;/strong&gt;. For instance, they could be made available through, &lt;strong&gt;configuration file (custom made by user or default file)&lt;/strong&gt; or in absence of this file, command the &lt;strong&gt;Retriever&lt;/strong&gt; to use defaults from code base.&lt;/p&gt;

&lt;p&gt;Writing code for the above workflow, which will take into account, different databases, is indeed an immaculate task. To combat such complexities, one of mentors, suggested &lt;a href=&#34;https://rstudio.github.io/reticulate/articles/introduction.html&#34; target=&#34;_blank&#34;&gt;Reticulate&lt;/a&gt; package. Its a package, that works wonders. Any package which resides in the world of Python and be imported in R and made to work in R environment.  After studying it theoretically, I was initially afraid of the execution speed, as it tries to combine two different worlds which dominate the space of Data Science. But, after giving it a number of trials, I fathomed that it executes pretty fast without any overhead, and can be incorporated directly to sync Python API and R API of &lt;strong&gt;Data Retriever&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I studied code of &lt;strong&gt;install function&lt;/strong&gt; of Python API deeply, to ensure that direct usage of its functions through &lt;strong&gt;Reticulate&lt;/strong&gt; encompasses all the detailed tasks which are required by R API. After variety of executions for different database supports, I figured that, using &lt;strong&gt;Reticulate&lt;/strong&gt; will be a boon. Synchronization of both the APIs requires minimal code and the pace of work has increased faster than ever. The Data Retriever might require an additional layer of detection of existance of Reticulate in the R environment as well.&lt;/p&gt;

&lt;p&gt;I expect to complete this task before coming weekend. In the coming week I plan to complete detection of &lt;strong&gt;Python&lt;/strong&gt; in &lt;strong&gt;Windows&lt;/strong&gt; machine for the Data Retriever.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>https://pranita-s.github.io/talk/example-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0530</pubDate>
      
      <guid>https://pranita-s.github.io/talk/example-talk/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>InfraGraf</title>
      <link>https://pranita-s.github.io/project/infragraf/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/infragraf/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I was part of this project during my tenure at Mphasis NEXT Labs as an Intern and Software Engineer.&lt;/li&gt;
&lt;li&gt;InfraGraf® is a Big Data complex event processing engine which enables enterprises to innovate and make strategic decisions regarding their technology infrastructure through actionable insights by correlation and causation analysis structured and unstructured data. It models enterprise technology infrastructure as complex systems consisting of interconnected servers, network devices, internet of things, industrial equipment etc. The powerful machine learning and graph theory based algorithms built into the platform identifies and predicts stand-alone as well as chain of events and incidents which could be related to system warnings, failures, outages, performance, availability and sub-optimal performances.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;My Role&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Leveraging power of Apache Spark Framework -

&lt;ul&gt;
&lt;li&gt;One of the data cleaning algorithms was taking more time than expected and an optimized approach for the same was crucial. I implemented the algorithm using Apache Spark in R programming language taking advantage of its distributed and parallel execution and robust implementation.&lt;/li&gt;
&lt;li&gt;For execution on cluster mode, I used AWS EC2 instances and S3 for storage. I also wrote python script for automating the process of cluster creation, code execution and cluster termination.&lt;/li&gt;
&lt;li&gt;It resulted in the decrease of the run time by 20 folds and was part of the product deployment.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Pattern Extraction from sequence data -

&lt;ul&gt;
&lt;li&gt;Assigned to a team of two.&lt;/li&gt;
&lt;li&gt;This is sub-project of the InfraGraf product. It is aimed at extracting all common patterns among given set event sequences with a minimum support and confidence. A common pattern is defined as a sequence which is subsequence among a defined minimum number of event sequences. Random walk based automata algorithm is built in C for this purpose. This algorithm is tested to give accurate results and implemented in real industrial applications.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Multi-server Architecture using Raspberry Pi</title>
      <link>https://pranita-s.github.io/project/raspberry/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/raspberry/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;This was my BE project. I was part of team of four.&lt;/li&gt;
&lt;li&gt;There has been an upsurge observed in the number of small scale and/or home-based businesses. This has been fueled by the internet which makes it very easy to set up one and offer services from the comfort of one’s home, accompanied by the reduction in costs of hardware devices in recent times. However, there are a myriad of networking needs of such offices in order to function smoothly, and most of them are expensive. Some of the most commonly needed ones are an always online file server, an intra-organization email server, a web server and a virtual private network service to stay secure online. We look at a way to cater to these networking needs by providing a solution which is cost effective and involves very low maintenance.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Our Solution&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To propose a fulfillment of the above requirements, we used Raspberry Pi. It is a mini computer which can be configured as Web Server, File Server, Email server and VPN at the same time. Being a cheaper alternative and having diverse capabailities, it posed as a great solution.&lt;/li&gt;
&lt;li&gt;We carried out its performace testing in the Central Computer Lab of our college with more than 150 students using the hosted servers at the same time.&lt;/li&gt;
&lt;li&gt;More details can be seen at &lt;a href=&#34;https://drive.google.com/file/d/1BiNaEVf0Hmayupoy5CkdALoDRIPvuvL8/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;https://drive.google.com/file/d/1BiNaEVf0Hmayupoy5CkdALoDRIPvuvL8/view?usp=sharing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Particle Swarm Optimization</title>
      <link>https://pranita-s.github.io/project/pso/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/pso/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The goal was to exibit the power of PSO with respect to DE as a tuner for SVM. For this comparison, we (a team of three) referred the paper &amp;ldquo;Easy over hard - A Case Study on Deep Learning&amp;rdquo; for the problem statement, data and performance metrics. DE has crossover and mutation functions for its implementation. We chose PSO for comparison as it has simpler implementation which revolves around the two update equations for velocity and position of particle. We wrote the code for PSO from scratch in Python.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;After testing PSO, we found that its performance metrics are at par with those of DE. But the time it takes for convergence is more, hence it is slightly slower than DE. It can be concluded that PSO can be used instead of DE, depending on the usecase and the important factors.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;My Role&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I contributed in the implementation of PSO algorithm in Python.&lt;/li&gt;
&lt;li&gt;Presentation for the same can be seen at - &lt;a href=&#34;https://docs.google.com/presentation/d/1FCd6igOw26W61A8BTVw7EHkDMXfhQ50d6YtcpuwGTMc/edit?usp=sharing&#34; target=&#34;_blank&#34;&gt;https://docs.google.com/presentation/d/1FCd6igOw26W61A8BTVw7EHkDMXfhQ50d6YtcpuwGTMc/edit?usp=sharing&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Search into Conversation</title>
      <link>https://pranita-s.github.io/project/alexa/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/alexa/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Conversational user interfaces are becoming increasingly used for a variety of research needs.
Some are voice-activated (such as Alexa, Siri, and Google Now), but many are text-oriented chatbots appearing as assistants in the context of a larger application. Text chatbots are being considered for providing help in using our products, but also for improving the legal research experience
Given a set of case law and judge data, answer research questions using a text-oriented, conversational interface.
For instance, if a user asks &amp;ldquo;List cases for Judge Lucy Koh&amp;rdquo;, the system would respond with a list of cases where Judge Koh is listed as a presiding judge.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Test Cases&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;U: List cases handled by Judge ADAMS&lt;/li&gt;
&lt;li&gt;B: THERE ARE 6 JUDGES with Llast name ADAMS and 2 JUDGES with FIRST NAME&lt;/li&gt;
&lt;li&gt;U: Last name ADAMS&lt;/li&gt;
&lt;li&gt;B: There are only 2 JUDGES with last name ADAMS who are currently on service with first name Henry Lee in Florida and John R in state of OHIO.&lt;/li&gt;
&lt;li&gt;U: The one in state of OHIO&lt;/li&gt;
&lt;li&gt;B: There were 0 cases handled by the judge&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Team&amp;rsquo;s Solution&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We trained DialogFlow with the provided data and then integrated it with Amazon Alexa as a medium of conversation. To accomplish this we used DialogFlow&amp;rsquo;s Alexa Exporter and Amazon Developer Dashboard. After training DialogFlow with the data, we generated Alexa compatible files and then used these files to create a new skill for Alexa.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;My Role&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I trained DialogFlow with help of the data by creating appropriate intents, entities and actions.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Solving Kinematics Word Problem</title>
      <link>https://pranita-s.github.io/project/rnn/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/rnn/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Problem Description&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Machine is fed with a Kinematics word problem. It has to parse and understand the problem, and decide which equation will be required to solve the problem from the three equations-

&lt;ul&gt;
&lt;li&gt;s = u + a*t&lt;/li&gt;
&lt;li&gt;v*v = u*u + 2*a*s&lt;/li&gt;
&lt;li&gt;s = u*t + 0.5*a*t*t&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;To achieve this, machine has to identify given entites such as velocity, displacement and time and also identify which entity has to be computed.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Existing related research papers concentrate on creating a question template to fit in the given entities and compute the missing one. But this prohibits the question solving capability of the machine to only free fall examples. Hence, I used RNN with LSTM network to train the machine with the questions and the label being the equation to solve it. I used NLP to make the understanding flexible as the machine has to identify details such as &amp;ldquo;at rest&amp;rdquo;,&amp;ldquo;initial velocity&amp;rdquo;,&amp;ldquo;final velocity&amp;rdquo;,&amp;ldquo;starting from rest&amp;rdquo; and also entites with different measuring  units such as metres per second, kilometers per hour etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recognition&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;I presented this work at Woman Who Code Conference held in Bangalore,India in March 2017 as a lightening talk speaker.&lt;/li&gt;
&lt;li&gt;More details about the work can be seen at &lt;a href=&#34;https://drive.google.com/file/d/1eWJSIztqPYhv__SGZO6onDPzCbP_i8Qb/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;https://drive.google.com/file/d/1eWJSIztqPYhv__SGZO6onDPzCbP_i8Qb/view?usp=sharing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Summarization of Document</title>
      <link>https://pranita-s.github.io/project/semantic/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/semantic/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I was part of the team during my tenure at Mphasis NEXT Labs as a Software Engineer.&lt;/li&gt;
&lt;li&gt;This project is aimed to summarize grammatically written English document by build a queriable directed graph based on semantics and context (i.e. Event and Action). The query on graph can retrieve information about action and its effect, and entity and its role. We adopted various NLP and text mining methodologies to build the graph and stored the graph in Neo4j for effective information retrieval.&lt;/li&gt;
&lt;li&gt;This project involved usage of R and Python programming language, CoreNLP package for finding co-references among sentences, tokenization and POS tagging, Senna framework for Semantic Role Labelling, Semafor for frame-semantic parsing and Neo4j framework for graph querying.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;My Role&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I implemented co-reference relationship builder using CoreNLP (which internally uses Stanford CoreNLP framework) for replacement of pronouns with their respective nouns.&lt;/li&gt;
&lt;li&gt;I translated retrieved relationship between prominent nouns and verbs from the document pre-processing to Neo4j graph&lt;/li&gt;
&lt;li&gt;(Team of two) We created a GUI in RShiny for a prototype demonstration&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Person Re-Identification System For Mobile Devices</title>
      <link>https://pranita-s.github.io/publication/person-re-identification/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/publication/person-re-identification/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mobile visual clothing search</title>
      <link>https://pranita-s.github.io/publication/clothing-search/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/publication/clothing-search/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pranita-s.github.io/blog/getting_started/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/blog/getting_started/</guid>
      <description>&lt;p&gt;+++ title = &amp;ldquo;Academic: the website designer for Hugo&amp;rdquo;&lt;/p&gt;

&lt;p&gt;date = 2016-04-20T00:00:00 lastmod = 2018-01-13T00:00:00 draft = false&lt;/p&gt;

&lt;p&gt;tags = [&amp;ldquo;academic&amp;rdquo;] summary = &amp;ldquo;Create a beautifully simple website or blog in under 10 minutes.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[header] image = &amp;ldquo;headers/getting-started.png&amp;rdquo; caption = &amp;ldquo;Image credit: Academic&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-default.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-default.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;Default&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-ocean.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-ocean.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;Ocean&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-dark.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-dark.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;Dark&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-forest.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-forest.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;Default&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-coffee-playfair.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-coffee-playfair.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;Coffee theme with Playfair font&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-1950s.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-1950s.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;1950s&amp;rdquo; +++&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
